---
title: Workshop on Meta-Learning (MetaLearn 2022)
description: "@NeurIPS 2022 <br> 13 December 2022 <br> (Virtual-Only)"

permalink: /2022/index.html
weight: -1
redirect_from: /2022/
---

### TL;DR: How can I participate?

The 2021 Workshop on Meta-Learning will be a series of streamed pre-recorded talks + live question-and-answer (Q&A) periods, and poster sessions on Gather.Town. You will be able to participate via our [NeurIPS.cc virtual workshop page](https://neurips.cc/virtual/2021/workshop/21867) (NeurIPS registration required) by:
- Watching the **livestream**: [link](https://neurips.cc/virtual/2021/workshop/21867)!
- Joining **Zoom to message questions to the moderator during the Q&As and panel discussion** (Link on the interal NeurIPS page).
- Joining the **poster sessions on Gather.Town**.
- Watching the **prerecorded videos** for posters, contributed talks and invited talks.
- Chatting with us and other participants on the workshop **RocketChat**!
- Asking questions on sli.do (Links below)

You can also:
- Read the **[contributed papers](#contributed-papers) on OpenReview**.
- Ask **panel discussion questions** here:

<center>
<div id="main_block">
        <iframe src="https://app.sli.do/event/gofQFfv6GTuPux8PebvmnR" height="100%" width="100%" style="min-height: 560px;"></iframe>
</div>
</center>

### News & Updates

<!--
- Dec. 11, 2020: Paper, supplementary materials and posters have been added to the [accepted papers](#accepted-papers) section!

- Dec. 11, 2020: Workshop day! Please check the "tl;dr" section above for participation instructions.

- Nov. 16, 2020: NeurIPS registration funding from the workshop for presenters and junior reviewers has been distributed. The NeurIPS conference also has a funding program [here](https://neurips.cc/Surveys/49).

- Nov. 14, 2020: The workshop [schedule](#schedule) has been finalized! You can also find it on [NeurIPS.cc](https://nips.cc/Conferences/2020/ScheduleMultitrack?event=16141).

- Oct. 30, 2020: Decisions have been sent out. Thank you to everyone who submitted or participated in [the reviewing process](#reviewing-mentorship)!

- Oct. 4, 2020: The submission portal has now closed and [the reviewing process](#reviewing-mentorship) has begun.

-->

- Dec. 13, 2020: Workshop day! Please check the "tl;dr" section above for participation instructions.
- Dec. 11, 2021: [Papers](#contributed-papers) are now released via the workshop's OpenReview!
- Oct. 12, 2021: The workshop [schedule](#schedule) has been added!
- Sep. 15, 2021: We have added a [reviewing guideline](#review-process) for both junior and senior reviewers and removed the 10-page appendix limit. 
- Sep. 14, 2021: We extended the paper submission deadline to September 29th.
- Sep. 5, 2021: We added a note to [formatting](#formatting), stating that we explicitly encourage shorter than 8-page submissions.
- Aug. 25, 2021: OpenReview open for [submissions](#submission-instructions)! [Reviewing mentorship sign-up & recommendation form](#reviewing-mentorship) released!

### Abstract

Recent years have seen rapid progress in meta-learning methods, which transfer knowledge across tasks and domains to efficiently learn new tasks, optimize the learning process itself, and even generate new learning methods from scratch. Meta-learning can be seen as the logical conclusion of the arc that machine learning has undergone in the last decade, from learning classifiers, to learning representations, and finally to learning algorithms that themselves acquire representations, classifiers, and policies for acting in environments. In practice, meta-learning has been shown to yield new state-of-the-art automated machine learning methods, novel deep learning architectures, and substantially improved one-shot learning systems. Moreover, improving one’s own learning capabilities through experience can also be viewed as a hallmark of intelligent beings, and neuroscience shows a strong connection between human and reward learning and the growing sub-field of meta-reinforcement learning. 

Some of the fundamental questions that this workshop aims to address are:

- How can we exploit our domain knowledge to guide the meta-learning process and make it more efficient?
- What are the meta-learning processes in nature (e.g., in humans), and how can we take inspiration from them?
- Which machine learning approaches are best suited for meta-learning, in which circumstances, and why?
- What principles can we learn from meta-learning to help us design the next generation of learning systems?

**In this year’s edition of the workshop, we propose the workshop to have the following four foci**, which are informed by recent developments in meta-learning:

- Are there broadly applicable desiderata for meta-learning algorithms (e.g., modularity, interpretability), or is this more a function of the application domain?
- Can we derive entirely new and generally applicable machine learning components (e.g., architectural blocks, learning rate schedules, optimizers, task sets) by meta-learning, and can they transfer to very different tasks?
- Can we derive prescriptions for algorithm design by looking at the properties of meta-learned systems?
- What is unique and common amongst various meta-learning settings, including few-shot learning, architecture search, hyperparameter optimization, etc.?

As prospective participants, we primarily target machine learning researchers interested in the questions and foci outlined above. Specific target communities within machine learning include, but are not limited to: meta-learning, AutoML, reinforcement learning, deep learning, optimization, evolutionary computation, and Bayesian optimization. We also invite submissions from researchers who study human learning and neuroscience, to provide a broad and interdisciplinary perspective to the attendees.

### Invited Speakers

<!-- Submit challenge questions for the speakers [here](https://forms.gle/DGEev5erxAmoi6eEA).  -->

- [Carlo Ciliberto](https://cciliber.github.io/) (UCL)
  <!--  **Title**  -->
- [Rosemary Ke](https://nke001.github.io/) (DeepMind)
  <!--   **Title**  -->
- [Luke Metz](http://lukemetz.com/) (Google)
  <!--  **Title**  -->
- [Mihaela van der Schaar](https://www.vanderschaar-lab.com/prof-mihaela-van-der-schaar/) (University of Cambridge)
  <!--  **Title**  -->
- [Eleni Triantafillou](https://www.cs.toronto.edu/~eleni/) (University of Toronto)
  <!--  **Title**  -->
- [Ying Wei](https://wei-ying.net/) (City University of Hong Kong)
  <!--  **Title**  -->

<!--
## Spotlights
### Morning Session
- [**Title**.](slides/metalearn2020-paper.pdf)
 *Authors*

### Afternoon Session
- [**Title**.](slides/metalearn2020-paper.pdf)
 *Authors*
-->

### Organizers

- [Fábio Ferreira](https://ml.informatik.uni-freiburg.de/people/ferreira/index.html) (Freiburg University)
- [Erin Grant](https://eringrant.github.io/) (UC Berkeley)
- [Frank Hutter](http://aad.informatik.uni-freiburg.de/people/hutter/) (Freiburg University)
- [Jonathan Schwarz](https://jonathan-schwarz.github.io/) (University College London, Deepmind)
- [Joaquin Vanschoren](http://www.win.tue.nl/~jvanscho/) (Eindhoven University of Technology)
- [Huaxiu Yao](https://huaxiuyao.mystrikingly.com/) (Stanford)

## Program

### Schedule

The workshop schedule is aligned with 11 AM to 8:30 PM [UTC](https://www.timeanddate.com/worldclock/timezone/utc); please see [this converter](https://www.timeanddate.com/worldclock/fixedtime.html?msg=Workshop+on+Meta-Learning+%28MetaLearn+2021%29&iso=20211213T11) for conversion to your specific time zone.

The schedule can also be found on the [workshop virtual site](https://neurips.cc/virtual/2021/workshop/21867).

| CST           | CET          | UTC            | EST            | PST             |
| ------------: | -----------: | -------------: | -------------: | --------------: |
|         19:00 |        12:00 |          11:00 |          06:00 |           03:00 | Introduction and opening remarks |
|         19:10 |        12:10 |          11:10 |          06:10 |           03:10 | **Invited talk 1**: Ying Wei, "Robust Meta-learning In the Wild" [Q&A](https://app.sli.do/event/eMMD9KMrtvXGVq8MTzTsRs) |
|         19:40 |        12:40 |          11:40 |          06:40 |           03:40 | **Contributed talk 1**: "[Meta-Learning Reliable Priors in the Function Space](https://openreview.net/forum?id=UHgSQilPX-7)" |
|         20:00 |        13:00 |          12:00 |          07:00 |           04:00 | Poster session 1 |
|         21:00 |        14:00 |          13:00 |          08:00 |           05:00 | **Invited talk 2**: Carlo Ciliberto, "The Theoretical and Practical Advantages of Conditional Meta-Learning" [Q&A](https://app.sli.do/event/eF7qGQEPgJWAmF5ZnHTU2s) |
|         21:30 |        14:30 |          13:30 |          08:30 |           05:30 | **Invited talk 3**: Mihaela van der Schaar, "Quantitative Epistemology– Empowering Human Meta-learning using Machine Learning." [Q&A](https://app.sli.do/event/iPxmemcmJMbx2rAkF6qzu2) |
|         22:00 |        15:00 |          14:00 |          09:00 |           06:00 | _Break_ |
|         23:00 |        16:00 |          15:00 |          10:00 |           07:00 | **Panel discussion** (Ask questions [here](https://app.sli.do/event/gofQFfv6GTuPux8PebvmnR)) |
|         00:00 |        17:00 |          16:00 |          11:00 |           08:00 | **Contributed talk 2**: "[Bootstrapped Meta-Learning](https://openreview.net/forum?id=l0p8mc_xSRN)" |
|         00:20 |        17:20 |          16:20 |          11:20 |           08:20 | **Invited talk 4**: ‪Nan Rosemary Ke‬, "Systematic evaluation of causal discovery in Visual Model based Reinforcement Learning" [Q&A](https://app.sli.do/event/sKX3ntNNRSG5kspfEEjpra) |
|         00:50 |        17:50 |          16:50 |          11:50 |           08:50 | Poster session 2 |
|         02:00 |        19:00 |          18:00 |          13:00 |           10:00 | **Invited talk 5**: Luke Metz, "Learned optimizers: The future of learning" [Q&A](https://app.sli.do/event/3gErnMS3vdePoSCcq31omD) |
|         02:30 |        19:30 |          18:30 |          13:30 |           10:30 | **Invited talk 6**: Eleni Triantafillou, "On the role of meta-learning for few-shot classification" [Q&A](https://app.sli.do/event/uNGvgfiYPd6boGHxKfRxuk) |
|         03:00 |        20:00 |          19:00 |          14:00 |           11:00 | **Contributed talk 3**: "[Offline Meta-Reinforcement Learning with Online Self-Supervision](https://openreview.net/forum?id=j8FYUjh_q2v)" |
|         03:20 |        20:20 |          19:20 |          14:20 |           11:20 | Poster session 3 |
|         04:30 |        21:30 |          20:30 |          15:30 |           12:30 | _End_ |

### Contributed Papers

To make it easier to find the posters, we list them below according to their location ID in our GatherTown room in ascending order (denoted in preceding brackets). A paid NeurIPS.cc registration is required to access the Gather.Town poster rooms; see the [tl;dr section](#tldr-how-can-i-participate) for access details.

#### Poster session 1 (12:00 UTC)
- (A2) [Open-Ended Learning Strategies for Learning Complex Locomotion Skills](https://openreview.net/forum?id=l8c9NYgA4Lw)
- (A3) [Neural Processes with Stochastic Attention: Paying more attention to the context dataset](https://openreview.net/forum?id=URep0STGewu)
- (B0) [Transformers Can Do Bayesian-Inference By Meta-Learning on Prior-Data](https://openreview.net/forum?id=h9yIMMjRoje)
- (B1) [On the Practical Consistency of Meta-Reinforcement Learning Algorithms](https://openreview.net/forum?id=xwQgKphwhFA)
- (C3) [Transfer Learning for Bayesian HPO with End-to-End Landmark Meta-Features](https://openreview.net/forum?id=wfD-fMD4StU)
- (F1) [Introducing Symmetries to Black Box Meta Reinforcement Learning](https://openreview.net/forum?id=LXmP-7uObH9)
- (F3) [Task Attended Meta-Learning for Few-Shot Learning](https://openreview.net/forum?id=D380IGEhAnF)
- (G0) [One Step at a Time: Pros and Cons of Multi-Step Meta-Gradient Reinforcement Learning](https://openreview.net/forum?id=QVx41_Ixgb9)
- (G1) [Bootstrapped Meta-Learning](https://openreview.net/forum?id=l0p8mc_xSRN)
- (G2) [Skill-based Meta-Reinforcement Learning](https://openreview.net/forum?id=jsV1-AQVEFY)
- (H2) [On the Role of Pre-training for Meta Few-Shot Learning](https://openreview.net/forum?id=rMb5uMu1vuj)

#### Poster session 2 (16:50 UTC)
- (A0) [Variational Task Encoders for Model-Agnostic Meta-Learning](https://openreview.net/forum?id=dfYhf5IuMPE)
- (B2) [Understanding Catastrophic Forgetting and Remembering in Continual Learning with Optimal Relevance Mapping](https://openreview.net/forum?id=Pvqe_hQEXTJ)
- (C1) [DARTS without a Validation Set: Optimizing the Marginal Likelihood](https://openreview.net/forum?id=661Wz3zOzlt)
- (C2) [Curriculum Meta-Learning for Few-shot Classification](https://openreview.net/forum?id=teRUKZdPJt6)
- (D0) [Successor Feature Neural Episodic Control](https://openreview.net/forum?id=e1Q2_jaE08J)
- (D1) [FedMix: A Simple and Communication-Efficient Alternative to Local Methods in Federated Learning](https://openreview.net/forum?id=6WhWweNk8gr)
- (F0) [A Nested Bi-level Optimization Framework for Robust Few Shot Learning](https://openreview.net/forum?id=OtokjoNoFu5)
- (G3) [Efficient Automated Online Experimentation with Multi-Fidelity](https://openreview.net/forum?id=c04LDyEm-N4)
- (H0) [Sign-MAML: Efficient Model-Agnostic Meta-Learning by SignSGD](https://openreview.net/forum?id=bd0UOwKS_6j)
- (H1) [A Preliminary Study on the Feature Representations of Transfer Learning and Gradient-Based Meta-Learning Techniques](https://openreview.net/forum?id=bkZRxSrCMf0)
- (H3) [Contrastive Embedding of Structured Space for Bayesian Optimization](https://openreview.net/forum?id=xFpkJUMS9te)
- (I0) [Hierarchical Few-Shot Generative Models](https://openreview.net/forum?id=INSai0E0VXN)

#### Poster session 3 (19:20 UTC)
- (A1) [Meta-learning from sparse recovery](https://openreview.net/forum?id=ODs0nDkjncI)
- (B3) [Few Shot Image Generation via Implicit Autoencoding of Support Sets](https://openreview.net/forum?id=fem00ckyS8t)
- (C0) [Meta-learning inductive biases of learning systems with Gaussian processes](https://openreview.net/forum?id=YPeusrnp28q)
- (D2) [Offline Meta-Reinforcement Learning with Online Self-Supervision](https://openreview.net/forum?id=j8FYUjh_q2v)
- (D3) [Studying BatchNorm Learning Rate Decay on Meta-Learning Inner-Loop Adaptation](https://openreview.net/forum?id=k9l1KkV4eQc)
- (E0) [Effect of diversity in Meta-Learning](https://openreview.net/forum?id=smeVtHQNtbe)
- (E1) [How to distribute data across tasks for meta-learning?](https://openreview.net/forum?id=o1plirEdhtZ)
- (E2) [Unsupervised Meta-Learning via Latent Space Energy-based Model of Symbol Vector Coupling](https://openreview.net/forum?id=-pLftu7EpXz)
- (E3) [Meta-Learning Reliable Priors in the Function Space](https://openreview.net/forum?id=UHgSQilPX-7)
- (F2) [A Meta-Gradient Approach to Learning Cooperative Multi-Agent Communication Topology](https://openreview.net/forum?id=VR0mCjFWGZw)

## Submission Instructions

~~tl;dr: Please submit via the workshop OpenReview submission page at [https://openreview.net/group?id=NeurIPS.cc/2021/Workshop/MetaLearn](https://openreview.net/group?id=NeurIPS.cc/2021/Workshop/MetaLearn).~~ The submission period has now passed.

### Important Dates

- Submission deadline: [September 29th, 2021, 11:59 PM AoE](https://www.timeanddate.com/worldclock/fixedtime.html?msg=MetaLearn%40NeurIPS+2021+Submission+Deadline&iso=20210929T235959&p1=3926)
- Author Notification: October 22nd, 2021, AoE
- Video recording to SlidesLive: November 1st, 2021, AoE
- Camera-ready submission (paper + poster) to OpenReview: November 29th, 2021, AoE
- Workshop: December 13th, 2021

### Formatting

We have provided a modified `.sty` file [here](neurips_2021.sty) that appropriately lists the name of the workshop when `\neuripsfinal` is enabled. Please use this style file in conjunction with the corresponding LaTeX `.tex` template from the [NeurIPS website](https://neurips.cc/Conferences/2021/PaperInformation/StyleFiles) to submit a final camera-ready copy. Both the submission and the camera-ready can be up to **8 pages** (excluding references) **and we explicitly encourage submitting works shorter than 8 pages** (e.g., works that may show preliminary but novel results).

### Publication

Accepted papers and supplementary material will be made available on the workshop website. However, these do not constitute archival publications and no formal workshop proceedings will be made available, meaning contributors are free to publish their work in archival journals or conferences.

### FAQ

1. Can supplementary material be added beyond the 8-page limit for submissions, and are there any restrictions on it?

   Yes, you may include additional supplementary material, but you should ensure that the main paper is self-contained, since looking at supplementary material is at the discretion of the reviewers. The supplementary material should also follow the same NeurIPS format as the paper.
   
1. Are references included in the 8-page limit?
   
   No, references will not count towards the page limit.

1. Can a submission to this workshop be submitted to another NeurIPS workshop in parallel?

   We discourage this, as it leads to more work for reviewers across multiple workshops. Our suggestion is to pick one workshop to submit to.

1. Can a paper be submitted to the workshop that has already appeared at a previous conference with published proceedings?

   We won't be accepting such submissions unless they have been adapted to contain significantly new results (where novelty is one of the qualities reviewers will be asked to evaluate).

1. Can a paper be submitted to the workshop that is currently under review or will be under review at a conference during the review phase?

   From our side, it is perfectly fine to submit a condensed version of a parallel conference submission if it is also fine for the conference in question. Our workshop does not have archival proceedings, and therefore parallel submissions of extended versions to other conferences are acceptable.
  
## Review Process

tl;dr: The review process will be **double-blind**. ~~Please sign up to be, or recommend, a reviewer via [https://forms.gle/EW4icbYv5uA8A13KA](https://forms.gle/EW4icbYv5uA8A13KA).~~ The review period has now passed.

### Important Dates

- Reviewer signup deadline: September 29th, 2021, AoE
- Assignments of reviewers to papers (start of review phase): October 1st, 2021
- Active discussion between junior & senior reviewers: October 1st to 15th, 2021
- First draft of review by junior reviewers: October 8th, 2021
- **Final reviewing deadline**: October 15th, 2021, AoE

### Reviewing Guidelines
We encourage all reviewers, both junior and senior, to check [our reviewing guidelines](https://docs.google.com/document/d/1vRdY8e2ttALw_kzxviejrhkVkiJlJ7YiS3yGm9jykB0/edit). 

### Reviewing Mentorship

Last year we trialed a new reviewer mentorship scheme aiming to improve the future pool of expert reviewers in machine learning. 61 Junior reviewers provided reviews guided by 39 senior reviewers, who gave them feedback and advice throughout the reviewing process. The program was a success with lots of discussion behind the scenes, and we're excited to renew the program this year.

If you would like to sign up, or recommend somebody, to be either a junior or senior reviewer, please fill out this [form](https://docs.google.com/forms/d/e/1FAIpQLSfAWp5swQk0fFP_QN9Agv5WlMWqmoVrP53ygmxLMKpuajjBVQ/viewform?usp=sf_link) by 29 September 2021.

Additionally, all submissions will be asked to provide **two** contacts who have agreed to review for the workshop. These volunteers can, of course, be authors of the submission, or people who have agreed to review on behalf of the authors. Depending on their experience reviewing, these contacts will be assigned to either a junior or senior reviewer role. All submissions will be ensured at least one senior reviewer, since we will still be directly recruiting for reviewers as in previous years.



<!--
## Accepted Papers ##

- [**Title**.](papers/paper.pdf)
 *Authors*
-->


## Program Committee

We thank the program committee (senior and junior reviewers) for shaping the excellent technical program; they are (in alphabetical order):

Aaron Klein,
Abhishek Gupta,
Alex De Sa,
Alexander Tornede,
Alexander Wang,
Andrei Alex Rusu,
Andrew Brock,
Aroof Aimen,
Artur Souza,
Aviral Kumar,
Badr AlKhamissi,
Benjamin Eysenbach,
Benjamin Letham,
Bradly C. Stadie,
Changbin Li,
Chen Zhao,
Chia Hsiang Kao,
Clément Bonnet,
Daniel Hernández-Lobato,
Davide Buffelli,
Eleni Triantafillou,
Eric Mitchell,
Fangqin Zhou,
Giorgio Giannone,
Hadi Samer Jomaa,
Haozhu Wang,
Homanga Bharadhwaj,
Huaxiu Yao,
Ievgen Redko,
Ishita Dasgupta,
Jake Snell,
Jaya Krishna Mandivarapu,
Jiajun Wu,
Johannes Von Oswald,
Jonas Hanselle,
Jonas Rothfuss,
Julien Niklas Siems,
Karsten Roth,
Kate Rakelly,
Kelvin Xu,
Lars Kotthoff,
Louis Kirsch,
Lucas Zimmer,
Luisa M Zintgraf,
Marius Lindauer,
Marvin Zhang,
Massimiliano Patacchiola,
Mateusz Ochal,
Maximilian Igl,
Mengye Ren,
Michael Chang,
Michael Y. Li,
Mihai Suteu,
Mike Huisman,
Mikhail Mekhedkin Meskhi,
Mingyu Kim,
Nasik Muhammad Nafi,
Nayan Saxena,
Nicholas I-Hsien Kuo,
Nico Courts,
Nikita Dhawan,
Ondrej Bohdal,
Paul Caron,
Pedro Sandoval-Segura,
Praneet Dutta,
Quentin Bouniot,
Ramnath Kumar,
Renkun Ni,
Sahil Manchanda,
Sean M. Hendryx,
Sharare Zehtabian,
Sreejan Kumar,
Sungryull Sohn,
Tejaswini Pedapati,
Thomas Elsken,
Tim Postuvan,
Valentin Guillet,
Valerio Perrone,
Yandong Li


## Past Workshops

[Workshop on Meta-Learning (MetaLearn 2017) @ NeurIPS 2017](https://meta-learn.github.io/2017/)

[Workshop on Meta-Learning (MetaLearn 2018) @ NeurIPS 2018](https://meta-learn.github.io/2018/)

[Workshop on Meta-Learning (MetaLearn 2019) @ NeurIPS 2019](https://meta-learn.github.io/2019/)

[Workshop on Meta-Learning (MetaLearn 2020) @ NeurIPS 2020](https://meta-learn.github.io/2020/)

[Workshop on Meta-Learning (MetaLearn 2021) @ NeurIPS 2021](https://meta-learn.github.io/2021/)

<!--
## Sponsors

We are grateful for the support of our sponsors, which enabled us to offer XX to several participants.
-->

## Contacts

For any further questions, you can contact us at <metalearn2021@googlegroups.com>.
